{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant general libraries.\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Spacy imports for NER.\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spacy large NL model and set a higher max_length.\n",
    "model = spacy.load(\"nl_core_news_lg\")\n",
    "model.max_length = 10000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kamers_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omit rows with missing text or date\n",
    "df = df[df['date'].notna()]\n",
    "df = df[df['text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataset by date if it wasn't already.\n",
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove unwanted characters.\n",
    "def remove_unwanted_chars(text):\n",
    "\n",
    "    # Replace \\n, \\t, and \\r with a space\n",
    "    cleaned_text = re.sub(r\"[\\n\\t\\r]\", \" \", str(text))\n",
    "    \n",
    "    # Remove the extra spaces\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "# Apply the text-cleaning function to the text column of the dataset.\n",
    "df[\"text\"] = df[\"text\"].apply(remove_unwanted_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve entities from textual data, using our SpaCy model.\n",
    "def get_entities(text):\n",
    "    doc = model(str(text))\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text, ent.label_))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the entity-tagging function to the 'text' column of our dataset, store in new column 'entities'.\n",
    "df['entities'] = df['text'].apply(get_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entity-tagged dataset.\n",
    "df.to_csv('kamers_text_tagged.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25178a3cdbf0b01d44076a1420e9720543679a0476c6ead08e157cb5b0ce819d"
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 ('python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
