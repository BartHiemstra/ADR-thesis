{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant general libraries.\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Stopword list\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "# Transformer\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('dutch')\n",
    "\n",
    "# Append custom words to be included in the stopword list.\n",
    "stop_words.append(['we', \"tweede\", \"kamer\", \" aanhangsel\",\"antwoord\",\"vraag\", \"bent\", \"ingezonden\", \"groet\", \"verzonden\", \"emailprocedure\", \"onderwerp\",\"verzoek\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kamers_text_tagged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to Pandas date if not already in that format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "# Sort by date if not already.\n",
    "df = df.sort_values(by='date')\n",
    "\n",
    "# Remove rows containing empty date or text columns, if there are still any.\n",
    "df = df[df['date'].notna()]\n",
    "df = df[df['text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text in preparation for BERTopic tagging.\n",
    "\n",
    "#replace \\n, \\t, and \\r with space in text column\n",
    "df['text'] = df['text'].astype(str)\n",
    "df.text = df.text.str.replace('\\n', ' ')\n",
    "df.text = df.text.str.replace('\\t', ' ')\n",
    "df.text = df.text.str.replace('\\r', ' ')\n",
    "\n",
    "#remove extra spaces with one space\n",
    "df.text = df.text.str.replace(' +', ' ')\n",
    "\n",
    "#remove numbers from text column\n",
    "df.text = df.apply(lambda row: re.sub(r'\\d+', '', row.text), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'text' column of the dataset to a list for easier use with BERTopic.\n",
    "doc_texts = df.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TFIDF-model which BERTopic uses, reduce frequent words.\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "# Define the BERTopic model.\n",
    "topic_model = BERTopic(verbose=True, calculate_probabilities=True, language='multilingual', ctfidf_model=ctfidf_model)\n",
    "\n",
    "# Fit model on textual data.\n",
    "topics, probs = topic_model.fit_transform(doc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce outliers; BERTopic by default will sort a lot of documents in the 'outlier' category of -1.clear_output\n",
    "# This function will turn those topics of value '-1' into any other probable non-negative topic, eliminating the heavy data loss.\n",
    "# Downside is that affected documents might not be as accurate in their topic representation.\n",
    "new_topics = topic_model.reduce_outliers(doc_texts, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionallh, update the topic_model.\n",
    "# Useful if we want to use the topic_model further, for applications like drawing topics over time with built=in BERTopic functions.\n",
    "# We only use BERTopic for tagging as a subprocess here, so the code is commented out.\n",
    "\n",
    "# topic_model.update_topics(doc_texts, topics=new_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block prints the outliers (topic values of '-1') that we would have had without outlier reduction applied.\n",
    "\n",
    "outlier_count = 0\n",
    "for topic in topics:\n",
    "    if topic == -1:\n",
    "        outlier_count += 1\n",
    "\n",
    "\n",
    "\n",
    "change_count = 0\n",
    "for i in range(len(topics)):\n",
    "    if topics[i] != new_topics[i]:\n",
    "        change_count += 1\n",
    "\n",
    "print(\"Number of '-1' topics:\", outlier_count)\n",
    "print(\"Number of elements that differ:\", change_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now assign the updated topics to our original topics variable.\n",
    "topics = new_topics.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the topics to our original DataFrame.\n",
    "for i, topic in enumerate(topics):\n",
    "    document_id = df.iloc[i]['id']\n",
    "    df.loc[df['id'] == document_id, 'topic_number'] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the topic_number column data type from 'float' to 'int'.\n",
    "df = df.astype({\"topic_number\":'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve topic words from the topic_model and assign them based on topic_number.\n",
    "def get_topic_words(topic_nr):\n",
    "    if topic_nr in topic_model.topic_representations_:\n",
    "        return topic_model.topic_representations_[topic_nr]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Apply the function to retrieve topic words and add 'topic_words' column to the DataFrame\n",
    "df['topic_words'] = df['topic_number'].apply(get_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our topic-tagged dataset.\n",
    "df.to_csv(\"kamers_text_tagged_topics.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25178a3cdbf0b01d44076a1420e9720543679a0476c6ead08e157cb5b0ce819d"
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 ('python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
